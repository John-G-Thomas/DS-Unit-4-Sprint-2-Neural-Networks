{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Train Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
    "\n",
    "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Apply regularization techniques to your model. \n",
    "\n",
    "*Don't forgot to switch to GPU on Colab!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cell\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import datetime\n",
    "# Our Model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from keras.layers import Dropout\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from keras.constraints import maxnorm\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "# Newer Imports \n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.layers import ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes((80000, 784), (80000,), (10000, 784), (10000,))\n"
     ]
    }
   ],
   "source": [
    "# Your Code Starts Here - load in data and spilt\n",
    "data = np.load('quickdraw10.npz')\n",
    "def load_quickdraw10npz(path):\n",
    "    X = path['arr_0']\n",
    "    y = path['arr_1']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, test_size = 0.1)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = load_quickdraw10npz(path=data)\n",
    "print(f'shapes{X_train.shape,y_train.shape,X_test.shape,y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptJ2b3wk62Ud"
   },
   "source": [
    "## Regularization\n",
    "\n",
    "Using your best performing model from the previous module, apply each of the following regularization strategies: \n",
    "* Early Stopping\n",
    "* Dropout\n",
    "* Weight Decay\n",
    "* Weight Constraint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model(neurons=64):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=784, kernel_initializer='glorot_uniform', activation='softsign', kernel_constraint=maxnorm(4)))\n",
    "    model.add(Dropout(0.0))\n",
    "    model.add(Dense(32, kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    optimizer = Adamax(lr=0.001, beta_1=0.2, beta_2=0.2, epsilon=1e-07)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USXjs7Hk71Hy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_5_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_5_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "   2/2500 [..............................] - ETA: 2:56 - loss: 124.1414 - accuracy: 0.1719WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0140s vs `on_train_batch_end` time: 0.1155s). Check your callbacks.\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 8.3276 - accuracy: 0.7691 ETA: 0s - loss: 8.4154 WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_5_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
      "2500/2500 [==============================] - 38s 15ms/step - loss: 8.3228 - accuracy: 0.7691 - val_loss: 2.2876 - val_accuracy: 0.8186\n",
      "Epoch 2/99\n",
      "2500/2500 [==============================] - 37s 15ms/step - loss: 1.2753 - accuracy: 0.8157 - val_loss: 0.9120 - val_accuracy: 0.8179\n",
      "Epoch 3/99\n",
      "2500/2500 [==============================] - 37s 15ms/step - loss: 0.8623 - accuracy: 0.8162 - val_loss: 0.8364 - val_accuracy: 0.8193\n",
      "Epoch 4/99\n",
      "2500/2500 [==============================] - 37s 15ms/step - loss: 0.8230 - accuracy: 0.8202 - val_loss: 0.9212 - val_accuracy: 0.7965\n",
      "Epoch 5/99\n",
      "2500/2500 [==============================] - 37s 15ms/step - loss: 0.8360 - accuracy: 0.8237 - val_loss: 0.8548 - val_accuracy: 0.8138\n",
      "Epoch 6/99\n",
      "2500/2500 [==============================] - 38s 15ms/step - loss: 0.8188 - accuracy: 0.8262 - val_loss: 0.9047 - val_accuracy: 0.7947 - loss: 0.8189 - ac\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2dd921a2278>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "logdir = os.path.join(\"logs\", \"EarlyStopping+L2_WeightDecay\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(512, kernel_regularizer=regularizers.l2(0.01)),\n",
    "    ReLU(negative_slope=.01),\n",
    "    Dense(512, kernel_regularizer=regularizers.l2(0.01)),\n",
    "    ReLU(negative_slope=.01),\n",
    "    Dense(512, kernel_regularizer=regularizers.l2(0.01)),\n",
    "    ReLU(negative_slope=.01),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "re_lu_15 (ReLU)              (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_16 (ReLU)              (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "re_lu_17 (ReLU)              (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 932,362\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "   2/2500 [..............................] - ETA: 1:44 - loss: 4.1589 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_begin` time: 0.0110s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0704s). Check your callbacks.\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 4.1589 - accuracy: 0.0064 - val_loss: 4.1589 - val_accuracy: 0.0073\n",
      "Epoch 2/99\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 4.1589 - accuracy: 0.0064 - val_loss: 4.1589 - val_accuracy: 0.0073\n",
      "Epoch 3/99\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 4.1589 - accuracy: 0.0064 - val_loss: 4.1589 - val_accuracy: 0.0073\n",
      "Epoch 4/99\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 4.1589 - accuracy: 0.0064 - val_loss: 4.1589 - val_accuracy: 0.0073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2dd92200240>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code Starts Here\n",
    "logdir = os.path.join(\"logs\", \"EarlyStopping-Loss\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3)\n",
    "\n",
    "def final_model(neurons=64):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=784, kernel_initializer='glorot_uniform', activation='softsign', kernel_constraint=maxnorm(4)))\n",
    "    model.add(Dropout(0.0))\n",
    "    model.add(Dense(32, kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    optimizer = Adamax(lr=0.001, beta_1=0.2, beta_2=0.2, epsilon=1e-07)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model.fit(X_train, y_train, epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_14 (ReLU)              (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                8256      \n",
      "=================================================================\n",
      "Total params: 141,760\n",
      "Trainable params: 141,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pScpa3nRRxCN"
   },
   "source": [
    "## Deploy\n",
    "\n",
    "Save your model's weights using the Checkpoint function. Try reloading the model and making inference on your validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 784) for input Tensor(\"flatten_41_input:0\", shape=(None, 1, 784), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 784) for input Tensor(\"flatten_41_input:0\", shape=(None, 1, 784), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 784) for input Tensor(\"flatten_41_input:0\", shape=(None, 1, 784), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
      "\n",
      "Epoch 00001: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 1.5288 - accuracy: 0.6976 - val_loss: 0.7606 - val_accuracy: 0.7771\n",
      "Epoch 2/32\n",
      "\n",
      "Epoch 00002: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.6685 - accuracy: 0.7968 - val_loss: 0.6624 - val_accuracy: 0.8041\n",
      "Epoch 3/32\n",
      "\n",
      "Epoch 00003: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.5806 - accuracy: 0.8234 - val_loss: 0.6033 - val_accuracy: 0.8196\n",
      "Epoch 4/32\n",
      "\n",
      "Epoch 00004: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.5309 - accuracy: 0.8392 - val_loss: 0.5638 - val_accuracy: 0.8347\n",
      "Epoch 5/32\n",
      "\n",
      "Epoch 00005: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.4961 - accuracy: 0.8510 - val_loss: 0.5382 - val_accuracy: 0.8423\n",
      "Epoch 6/32\n",
      "\n",
      "Epoch 00006: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.4649 - accuracy: 0.8599 - val_loss: 0.5513 - val_accuracy: 0.8409\n",
      "Epoch 7/32\n",
      "\n",
      "Epoch 00007: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.4424 - accuracy: 0.8673 - val_loss: 0.5451 - val_accuracy: 0.8446\n",
      "Epoch 8/32\n",
      "\n",
      "Epoch 00008: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.4205 - accuracy: 0.8728 - val_loss: 0.5435 - val_accuracy: 0.8473\n",
      "Epoch 9/32\n",
      "\n",
      "Epoch 00009: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.4005 - accuracy: 0.8794 - val_loss: 0.5213 - val_accuracy: 0.8531\n",
      "Epoch 10/32\n",
      "\n",
      "Epoch 00010: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.3844 - accuracy: 0.8832 - val_loss: 0.5260 - val_accuracy: 0.8561\n",
      "Epoch 11/32\n",
      "\n",
      "Epoch 00011: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.3653 - accuracy: 0.8895 - val_loss: 0.5750 - val_accuracy: 0.8572\n",
      "Epoch 12/32\n",
      "\n",
      "Epoch 00012: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.3715 - accuracy: 0.8914 - val_loss: 0.5553 - val_accuracy: 0.8550\n",
      "Epoch 13/32\n",
      "\n",
      "Epoch 00013: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.3600 - accuracy: 0.8948 - val_loss: 0.5769 - val_accuracy: 0.8512\n",
      "Epoch 14/32\n",
      "\n",
      "Epoch 00014: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.3363 - accuracy: 0.8989 - val_loss: 0.5896 - val_accuracy: 0.8540\n",
      "Epoch 15/32\n",
      "\n",
      "Epoch 00015: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.3266 - accuracy: 0.9027 - val_loss: 0.6601 - val_accuracy: 0.8488\n",
      "Epoch 16/32\n",
      "\n",
      "Epoch 00016: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.3105 - accuracy: 0.9055 - val_loss: 0.6559 - val_accuracy: 0.8562\n",
      "Epoch 17/32\n",
      "\n",
      "Epoch 00017: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.3057 - accuracy: 0.9072 - val_loss: 0.5863 - val_accuracy: 0.8582\n",
      "Epoch 18/32\n",
      "\n",
      "Epoch 00018: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.2978 - accuracy: 0.9098 - val_loss: 0.6145 - val_accuracy: 0.8597\n",
      "Epoch 19/32\n",
      "\n",
      "Epoch 00019: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.2973 - accuracy: 0.9101 - val_loss: 0.6616 - val_accuracy: 0.8532\n",
      "Epoch 20/32\n",
      "\n",
      "Epoch 00020: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.2830 - accuracy: 0.9140 - val_loss: 0.6678 - val_accuracy: 0.8511\n",
      "Epoch 21/32\n",
      "\n",
      "Epoch 00021: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.2843 - accuracy: 0.9152 - val_loss: 0.7220 - val_accuracy: 0.8504\n",
      "Epoch 22/32\n",
      "\n",
      "Epoch 00022: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.2962 - accuracy: 0.9179 - val_loss: 0.7761 - val_accuracy: 0.8519\n",
      "Epoch 23/32\n",
      "\n",
      "Epoch 00023: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.2567 - accuracy: 0.9205 - val_loss: 0.8065 - val_accuracy: 0.8395\n",
      "Epoch 24/32\n",
      "\n",
      "Epoch 00024: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.2610 - accuracy: 0.9200 - val_loss: 0.7971 - val_accuracy: 0.8468\n",
      "Epoch 25/32\n",
      "\n",
      "Epoch 00025: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.2486 - accuracy: 0.9233 - val_loss: 0.8788 - val_accuracy: 0.8470\n",
      "Epoch 26/32\n",
      "\n",
      "Epoch 00026: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.2431 - accuracy: 0.9257 - val_loss: 0.9222 - val_accuracy: 0.8461\n",
      "Epoch 27/32\n",
      "\n",
      "Epoch 00027: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.2463 - accuracy: 0.9255 - val_loss: 0.8539 - val_accuracy: 0.8512\n",
      "Epoch 28/32\n",
      "\n",
      "Epoch 00028: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.2303 - accuracy: 0.9281 - val_loss: 0.9710 - val_accuracy: 0.8523\n",
      "Epoch 29/32\n",
      "\n",
      "Epoch 00029: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.2371 - accuracy: 0.9277 - val_loss: 0.9303 - val_accuracy: 0.8447\n",
      "Epoch 30/32\n",
      "\n",
      "Epoch 00030: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.2299 - accuracy: 0.9306 - val_loss: 1.0383 - val_accuracy: 0.8529\n",
      "Epoch 31/32\n",
      "\n",
      "Epoch 00031: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.2227 - accuracy: 0.9318 - val_loss: 1.0067 - val_accuracy: 0.8496\n",
      "Epoch 32/32\n",
      "\n",
      "Epoch 00032: saving model to weights_best.h6\n",
      "2500/2500 - 4s - loss: 0.2255 - accuracy: 0.9314 - val_loss: 1.0109 - val_accuracy: 0.8467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2dd952cb358>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpoint = tf.keras.callbacks.ModelCheckpoint(\"weights_best.h6\",\n",
    "                                            verbose=1, \n",
    "                                            save_weights_only=True)\n",
    "\n",
    "def create_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      Flatten(input_shape=(1, 784)),\n",
    "      Dense(128),\n",
    "      ReLU(negative_slope=.01),\n",
    "      Dense(128),\n",
    "      ReLU(negative_slope=.01),\n",
    "      Dense(128),\n",
    "      ReLU(negative_slope=.01),\n",
    "      Dense(10, activation='softmax')\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=32,batch_size=32,\n",
    "          validation_data=(X_test,y_test),\n",
    "          verbose=2,\n",
    "          callbacks=[cpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 719us/step - loss: 1.0109 - accuracy: 0.8467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0109076499938965, 0.8467000126838684]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cqpHQt_SIbW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_43 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "re_lu_124 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_125 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_126 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 134,794\n",
      "Trainable params: 134,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Your Code Starts Here\n",
    "m = create_model()  # Start with same architecture\n",
    "m.load_weights('./weights_best.h6')  # Load instead of train\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 784) for input Tensor(\"flatten_43_input:0\", shape=(None, 1, 784), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 784) for input Tensor(\"flatten_43_input:0\", shape=(None, 1, 784), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
      "313/313 [==============================] - 0s 722us/step - loss: 1.0109 - accuracy: 0.8467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0109076499938965, 0.8467000126838684]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model(neurons=64):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=784, kernel_initializer='glorot_uniform', activation='softsign', kernel_constraint=maxnorm(4)))\n",
    "    model.add(Dropout(0.0))\n",
    "    model.add(Dense(32, kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    optimizer = Adamax(lr=0.001, beta_1=0.2, beta_2=0.2, epsilon=1e-07)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 784) for input Tensor(\"flatten_46_input:0\", shape=(None, 1, 784), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 784) for input Tensor(\"flatten_46_input:0\", shape=(None, 1, 784), dtype=float32), but it was called on an input with incompatible shape (32, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 784) for input Tensor(\"flatten_46_input:0\", shape=(None, 1, 784), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
      "\n",
      "Epoch 00001: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 1.0959 - accuracy: 0.6631 - val_loss: 0.8528 - val_accuracy: 0.7387\n",
      "Epoch 2/32\n",
      "\n",
      "Epoch 00002: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.7883 - accuracy: 0.7558 - val_loss: 0.7728 - val_accuracy: 0.7640\n",
      "Epoch 3/32\n",
      "\n",
      "Epoch 00003: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.7286 - accuracy: 0.7743 - val_loss: 0.7392 - val_accuracy: 0.7751\n",
      "Epoch 4/32\n",
      "\n",
      "Epoch 00004: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.6938 - accuracy: 0.7839 - val_loss: 0.7084 - val_accuracy: 0.7837\n",
      "Epoch 5/32\n",
      "\n",
      "Epoch 00005: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.6666 - accuracy: 0.7943 - val_loss: 0.6936 - val_accuracy: 0.7938\n",
      "Epoch 6/32\n",
      "\n",
      "Epoch 00006: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.6379 - accuracy: 0.8024 - val_loss: 0.6690 - val_accuracy: 0.8021\n",
      "Epoch 7/32\n",
      "\n",
      "Epoch 00007: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.6249 - accuracy: 0.8056 - val_loss: 0.6679 - val_accuracy: 0.7984\n",
      "Epoch 8/32\n",
      "\n",
      "Epoch 00008: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.6114 - accuracy: 0.8101 - val_loss: 0.6464 - val_accuracy: 0.8043\n",
      "Epoch 9/32\n",
      "\n",
      "Epoch 00009: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.5961 - accuracy: 0.8142 - val_loss: 0.6327 - val_accuracy: 0.8102\n",
      "Epoch 10/32\n",
      "\n",
      "Epoch 00010: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.5826 - accuracy: 0.8187 - val_loss: 0.6250 - val_accuracy: 0.8096\n",
      "Epoch 11/32\n",
      "\n",
      "Epoch 00011: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.5714 - accuracy: 0.8230 - val_loss: 0.6264 - val_accuracy: 0.8126\n",
      "Epoch 12/32\n",
      "\n",
      "Epoch 00012: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.5662 - accuracy: 0.8243 - val_loss: 0.6189 - val_accuracy: 0.8149\n",
      "Epoch 13/32\n",
      "\n",
      "Epoch 00013: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.5530 - accuracy: 0.8283 - val_loss: 0.6127 - val_accuracy: 0.8171\n",
      "Epoch 14/32\n",
      "\n",
      "Epoch 00014: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.5459 - accuracy: 0.8299 - val_loss: 0.6087 - val_accuracy: 0.8183\n",
      "Epoch 15/32\n",
      "\n",
      "Epoch 00015: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.5441 - accuracy: 0.8323 - val_loss: 0.5977 - val_accuracy: 0.8183\n",
      "Epoch 16/32\n",
      "\n",
      "Epoch 00016: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.5341 - accuracy: 0.8341 - val_loss: 0.5927 - val_accuracy: 0.8222\n",
      "Epoch 17/32\n",
      "\n",
      "Epoch 00017: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.5295 - accuracy: 0.8354 - val_loss: 0.5882 - val_accuracy: 0.8219\n",
      "Epoch 18/32\n",
      "\n",
      "Epoch 00018: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.5209 - accuracy: 0.8384 - val_loss: 0.5833 - val_accuracy: 0.8251\n",
      "Epoch 19/32\n",
      "\n",
      "Epoch 00019: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.5166 - accuracy: 0.8396 - val_loss: 0.5870 - val_accuracy: 0.8230\n",
      "Epoch 20/32\n",
      "\n",
      "Epoch 00020: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.5088 - accuracy: 0.8429 - val_loss: 0.5756 - val_accuracy: 0.8285\n",
      "Epoch 21/32\n",
      "\n",
      "Epoch 00021: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.5055 - accuracy: 0.8435 - val_loss: 0.5761 - val_accuracy: 0.8260\n",
      "Epoch 22/32\n",
      "\n",
      "Epoch 00022: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.4972 - accuracy: 0.8452 - val_loss: 0.5698 - val_accuracy: 0.8272\n",
      "Epoch 23/32\n",
      "\n",
      "Epoch 00023: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.4951 - accuracy: 0.8463 - val_loss: 0.5774 - val_accuracy: 0.8265\n",
      "Epoch 24/32\n",
      "\n",
      "Epoch 00024: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.4912 - accuracy: 0.8487 - val_loss: 0.5727 - val_accuracy: 0.8271\n",
      "Epoch 25/32\n",
      "\n",
      "Epoch 00025: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.4907 - accuracy: 0.8468 - val_loss: 0.5624 - val_accuracy: 0.8307\n",
      "Epoch 26/32\n",
      "\n",
      "Epoch 00026: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.4859 - accuracy: 0.8502 - val_loss: 0.5563 - val_accuracy: 0.8308\n",
      "Epoch 27/32\n",
      "\n",
      "Epoch 00027: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.4795 - accuracy: 0.8513 - val_loss: 0.5479 - val_accuracy: 0.8328\n",
      "Epoch 28/32\n",
      "\n",
      "Epoch 00028: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.4775 - accuracy: 0.8519 - val_loss: 0.5611 - val_accuracy: 0.8318\n",
      "Epoch 29/32\n",
      "\n",
      "Epoch 00029: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.4750 - accuracy: 0.8528 - val_loss: 0.5559 - val_accuracy: 0.8317\n",
      "Epoch 30/32\n",
      "\n",
      "Epoch 00030: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.4703 - accuracy: 0.8538 - val_loss: 0.5529 - val_accuracy: 0.8318\n",
      "Epoch 31/32\n",
      "\n",
      "Epoch 00031: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.4651 - accuracy: 0.8560 - val_loss: 0.5445 - val_accuracy: 0.8362\n",
      "Epoch 32/32\n",
      "\n",
      "Epoch 00032: saving model to weights_best.h7\n",
      "2500/2500 - 3s - loss: 0.4580 - accuracy: 0.8580 - val_loss: 0.5478 - val_accuracy: 0.8349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2dd953df128>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpoint = tf.keras.callbacks.ModelCheckpoint(\"weights_best.h7\",\n",
    "                                            verbose=1, \n",
    "                                            save_weights_only=True)\n",
    "\n",
    "def create_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      Flatten(input_shape=(1, 784)),\n",
    "      Dense(128),\n",
    "      ReLU(negative_slope=.01),\n",
    "      Dense(128,kernel_initializer='glorot_uniform', activation='softsign', kernel_constraint=maxnorm(4)),\n",
    "      ReLU(negative_slope=.01),\n",
    "      Dense(128,kernel_initializer='glorot_uniform', activation='sigmoid'),\n",
    "      ReLU(negative_slope=.01),\n",
    "      Dense(10, activation='softmax')\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer='Adamax',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=32,batch_size=32,\n",
    "          validation_data=(X_test,y_test),\n",
    "          verbose=2,\n",
    "          callbacks=[cpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 697us/step - loss: 0.5478 - accuracy: 0.8349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5477806925773621, 0.8349000215530396]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_47 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "re_lu_136 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_137 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "re_lu_138 (ReLU)             (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 134,794\n",
      "Trainable params: 134,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = create_model()  # Start with same architecture\n",
    "m.load_weights('./weights_best.h7')  # Load instead of train\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 784) for input Tensor(\"flatten_47_input:0\", shape=(None, 1, 784), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 784) for input Tensor(\"flatten_47_input:0\", shape=(None, 1, 784), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
      "313/313 [==============================] - 0s 709us/step - loss: 0.5478 - accuracy: 0.8349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5477806925773621, 0.8349000215530396]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKbr1gRg9BXs"
   },
   "source": [
    "### Stretch Goals\n",
    "- Mount your Google Drive to Colab to persist your model checkpoint files. \n",
    "- Research L2 normalization (weight decay)\n",
    "- Write a custom callback function to stop training after you reach .88 validation accuracy. \n",
    "- Select a new dataset and apply a neural network to it.\n",
    "- Research TensorFlow Serving\n",
    "- Play [QuickDraw](https://quickdraw.withgoogle.com/data)\n",
    "- Create a static webpage using TensorFlow.js to serve a model. Check out [Teachable Machine Learning](https://teachablemachine.withgoogle.com/) for ideas. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_434_Deploy_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
